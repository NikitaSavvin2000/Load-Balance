{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T20:00:57.230805Z",
     "start_time": "2023-09-13T20:00:55.193558Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "apfs_df = pd.read_csv(r'Initial_data/ac_power_from_storage.csv')\n",
    "apts_df = pd.read_csv(r'Initial_data/ac_power_to_storage.csv')\n",
    "gc_df = pd.read_csv(r'Initial_data/grid_consumption.csv')\n",
    "gf_df = pd.read_csv(r'Initial_data/grid_feed.csv')\n",
    "pp_df = pd.read_csv(r'Initial_data/pv_production.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82b76ca2ebf878e",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad73b87351bba15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T20:01:07.249390Z",
     "start_time": "2023-09-13T20:00:57.214326Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Convert the time column to a time type'''\n",
    "\n",
    "apfs_df['time'] = pd.to_datetime(apfs_df['time'])\n",
    "apts_df['time'] = pd.to_datetime(apts_df['time'])\n",
    "gc_df['time'] = pd.to_datetime(gc_df['time'])\n",
    "gf_df['time'] = pd.to_datetime(gf_df['time'])\n",
    "pp_df['time'] = pd.to_datetime(pp_df['time'])\n",
    "gc_df.to_csv(r'result/gen.csv', index=False)\n",
    "\n",
    "'''Set the time as an index'''\n",
    "\n",
    "apfs_df.set_index('time', inplace=True)\n",
    "apts_df.set_index('time', inplace=True)\n",
    "gc_df.set_index('time', inplace=True)\n",
    "gf_df.set_index('time', inplace=True)\n",
    "pp_df.set_index('time', inplace=True)\n",
    "gc_df.to_csv(r'result/gen1.csv', index=False)\n",
    "\n",
    "\n",
    "'''Convert the column of values to float type'''\n",
    "\n",
    "apfs_df['ac_power_from_storage'] = apfs_df['ac_power_from_storage'].astype(float)\n",
    "apts_df['ac_power_to_storage'] = apts_df['ac_power_to_storage'].astype(float)\n",
    "gc_df['grid_consumption'] = gc_df['grid_consumption'].astype(float)\n",
    "gf_df['grid_feed'] = gf_df['grid_feed'].astype(float)\n",
    "pp_df['pv_production'] = pp_df['pv_production'].astype(float)\n",
    "gc_df.to_csv(r'result/gen2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мердж данных. Здесь я использовал мердж для того, чтобы в нашем датасете произвести расчет нагрузки энергопотребления до момента ресэмплирования. По итогу в файле P_l получаем реальные данные(без подстановки нулей) с разрывами в значениях.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Чтение всех датасетов\n",
    "apfs_df = pd.read_csv(r'Initial_data/ac_power_from_storage.csv')\n",
    "apts_df = pd.read_csv(r'Initial_data/ac_power_to_storage.csv')\n",
    "gc_df = pd.read_csv(r'Initial_data/grid_consumption.csv')\n",
    "gf_df = pd.read_csv(r'Initial_data/grid_feed.csv')\n",
    "pp_df = pd.read_csv(r'Initial_data/pv_production.csv')\n",
    "\n",
    "# Объединение датасетов\n",
    "merged_df = apfs_df.merge(apts_df, on='time', how='outer') \\\n",
    "                  .merge(gc_df, on='time', how='outer') \\\n",
    "                  .merge(gf_df, on='time', how='outer') \\\n",
    "                  .merge(pp_df, on='time', how='outer')\n",
    "\n",
    "# Преобразование столбца 'datetime' в datetime\n",
    "merged_df['time'] = pd.to_datetime(merged_df['time'])\n",
    "\n",
    "# Установка 'datetime' как индекс\n",
    "merged_df.set_index('time', inplace=True)\n",
    "\n",
    "# Рассчитываем P_l\n",
    "merged_df['P_l'] = merged_df['pv_production'] + merged_df['grid_consumption'] + \\\n",
    "                   merged_df['ac_power_from_storage'] - merged_df['grid_feed'] - \\\n",
    "                   merged_df['ac_power_to_storage']\n",
    "\n",
    "# Сохраняем результат в CSV\n",
    "merged_df.to_csv(r'result/merged_df_with_P_l.csv')\n",
    "\n",
    "# Выбираем только столбцы 'time' и 'P_l' из merged_df\n",
    "result_df = merged_df[['P_l']]\n",
    "\n",
    "# Сохраняем результат в CSV\n",
    "result_df.to_csv(r'result/P_l.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18f3355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Код аналогичен верхнему, только сделал ресэмплирование по 5 мин\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Чтение всех датасетов\n",
    "apfs_df = pd.read_csv(r'Initial_data/ac_power_from_storage.csv')\n",
    "apts_df = pd.read_csv(r'Initial_data/ac_power_to_storage.csv')\n",
    "gc_df = pd.read_csv(r'Initial_data/grid_consumption.csv')\n",
    "gf_df = pd.read_csv(r'Initial_data/grid_feed.csv')\n",
    "pp_df = pd.read_csv(r'Initial_data/pv_production.csv')\n",
    "\n",
    "# Объединение датасетов\n",
    "merged_df = apfs_df.merge(apts_df, on='time', how='outer') \\\n",
    "                  .merge(gc_df, on='time', how='outer') \\\n",
    "                  .merge(gf_df, on='time', how='outer') \\\n",
    "                  .merge(pp_df, on='time', how='outer')\n",
    "\n",
    "# Преобразование столбца 'datetime' в datetime\n",
    "merged_df['time'] = pd.to_datetime(merged_df['time'])\n",
    "\n",
    "# Установка 'datetime' как индекс\n",
    "merged_df.set_index('time', inplace=True)\n",
    "\n",
    "# Рассчитываем P_l\n",
    "merged_df['P_l'] = merged_df['pv_production'] + merged_df['grid_consumption'] + \\\n",
    "                   merged_df['ac_power_from_storage'] - merged_df['grid_feed'] - \\\n",
    "                   merged_df['ac_power_to_storage']\n",
    "\n",
    "# Сохраняем результат в CSV\n",
    "merged_df.to_csv(r'result/merged_df_with_P_l.csv')\n",
    "\n",
    "# Выбираем только столбцы 'time' и 'P_l' из merged_df\n",
    "result_df = merged_df[['P_l']]\n",
    "\n",
    "# Сохраняем результат в CSV\n",
    "result_df.to_csv(r'result/P_l.csv')\n",
    "\n",
    "# Create an empty DataFrame with the time index\n",
    "index = pd.date_range(start_date, end_date, freq='5T')\n",
    "df_general = pd.DataFrame(index=index)\n",
    "\n",
    "# Сохраняем пустой DataFrame в CSV\n",
    "df_general.to_csv(r'result/df_general.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "445f679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь мы убираем нули из нашего датасета\n",
    "import pandas as pd\n",
    "\n",
    "# Загрузите данные P_l из файла P_l.csv\n",
    "df_P_l = pd.read_csv(r'result/P_l.csv')\n",
    "\n",
    "# Преобразуйте столбец 'time' в datetime и установите его в качестве индекса\n",
    "df_P_l['time'] = pd.to_datetime(df_P_l['time'])\n",
    "df_P_l.set_index('time', inplace=True)\n",
    "\n",
    "# Укажите частоту, с которой вы хотите пересэмплировать данные (например, '5T' для 5 минут)\n",
    "resample_frequency = '5T'\n",
    "\n",
    "# Пересэмплируйте данные с использованием суммирования для заполнения пропусков\n",
    "df_resampled = df_P_l.resample(resample_frequency).sum()\n",
    "\n",
    "# Замените нули на NaN\n",
    "df_resampled['P_l'] = df_resampled['P_l'].where(df_resampled['P_l'] != 0, pd.NA)\n",
    "\n",
    "# Сохраните результат в CSV\n",
    "df_resampled.to_csv(r'result/filled_P_l.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41135f351f6c11a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T20:01:14.988925Z",
     "start_time": "2023-09-13T20:01:07.441368Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Твой старый код, где образуются нули в разрывах\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_date = '2016-06-10 16:50:00+00:00'\n",
    "end_date = '2023-09-09 00:00:00+00:00'\n",
    "\n",
    "columns1 = ['time', 'P_l']\n",
    "df_P_l = pd.DataFrame(columns=columns1)\n",
    "\n",
    "columns2 = ['time', 'P_pv', 'P_fu', 'P_fs', 'P_tu', 'P_ts', 'P_l']\n",
    "df_general = pd.DataFrame(columns=columns2)\n",
    "\n",
    "iteration_date = start_date\n",
    "time_delta = pd.Timedelta(minutes=5)\n",
    "\n",
    "while iteration_date < end_date:\n",
    "    P_pv = g_pp_df['pv_production'][iteration_date]\n",
    "    P_fu = g_gc_df['grid_consumption'][iteration_date]\n",
    "    P_fs = g_apfs_df['ac_power_from_storage'][iteration_date]\n",
    "    P_tu = g_gf_df['grid_feed'][iteration_date]\n",
    "    P_ts = g_apts_df['ac_power_to_storage'][iteration_date]\n",
    "    \n",
    "    P_l = P_pv + P_fu + P_fs - (P_tu + P_ts)\n",
    "    \n",
    "    new_row1 = {'time': iteration_date, 'P_l': P_l}\n",
    "    new_row2 = {\n",
    "        'time': iteration_date,\n",
    "        'P_pv': P_pv, 'P_fu': P_fu, \n",
    "        'P_fs': P_fs, 'P_tu': P_tu, \n",
    "        'P_ts': P_ts, 'P_l': P_l\n",
    "    }\n",
    "    df_P_l = pd.concat([df_P_l, pd.DataFrame([new_row1])], ignore_index=True)\n",
    "    df_general = pd.concat([df_general, pd.DataFrame([new_row2])], ignore_index=True)\n",
    "    \n",
    "    iteration_date = datetime.strptime(iteration_date, '%Y-%m-%d %H:%M:%S%z')\n",
    "    iteration_date += time_delta\n",
    "    iteration_date = iteration_date.strftime('%Y-%m-%d %H:%M:%S%z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bf05801acaa69c21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T20:05:39.294401Z",
     "start_time": "2023-09-13T20:05:39.206395Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_P_l['P_l'] = df_P_l['P_l'].round(3)\n",
    "df_general['P_l'] = df_general['P_l'].round(3)\n",
    "\n",
    "df_P_l.to_csv(r'result/P_l.csv', index=False)\n",
    "df_general.to_csv(r'result/general.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "283cefbb4b34fcd0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g_pp_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7g/m6dqj4h97n3fmsx32gys7r7w0000gn/T/ipykernel_2798/3178479424.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_general\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate the components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_general\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P_pv'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_pp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pv_production'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_general\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P_fu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_gc_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'grid_consumption'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_general\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'P_fs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_apfs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ac_power_from_storage'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g_pp_df' is not defined"
     ]
    }
   ],
   "source": [
    "'''Updated version of code. Optimize the calculation loop using vectorized operations_код не актуален, он ускоряет процесс обработки твоего кода, но проставляет нули в разрывах''' \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create an empty DataFrame with the time index\n",
    "index = pd.date_range(start_date, end_date, freq='5T')\n",
    "df_general = pd.DataFrame(index=index)\n",
    "# Calculate the components\n",
    "df_general['P_pv'] = g_pp_df['pv_production']\n",
    "df_general['P_fu'] = g_gc_df['grid_consumption']\n",
    "df_general['P_fs'] = g_apfs_df['ac_power_from_storage']\n",
    "df_general['P_tu'] = g_gf_df['grid_feed']\n",
    "df_general['P_ts'] = g_apts_df['ac_power_to_storage']\n",
    "\n",
    "# Calculate P_l in one go\n",
    "df_general['P_l'] = df_general['P_pv'] + df_general['P_fu'] + df_general['P_fs'] - (df_general['P_tu'] + df_general['P_ts'])\n",
    "\n",
    "# Round the 'P_l' column\n",
    "df_general['P_l'] = df_general['P_l'].round(3)\n",
    "df_P_l['P_l'] = df_P_l['P_l'].round(3)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_general.to_csv(r'result/general.csv')\n",
    "df_P_l.to_csv(r'result/P_l.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
